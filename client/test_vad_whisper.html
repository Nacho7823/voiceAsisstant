<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Traductor de Voz en Tiempo Real</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif;
            margin: 0;
            padding: 2em;
            background-color: #f4f7f6;
            display: grid;
            place-items: center;
            min-height: 90vh;
        }
        main {
            width: 100%;
            max-width: 800px;
            background: #ffffff;
            border-radius: 12px;
            box-shadow: 0 8px 32px rgba(0, 0, 0, 0.07);
            padding: 2.5em;
            border: 1px solid #e0e0e0;
        }
        h1 {
            color: #2c3e50;
            text-align: center;
            margin-top: 0;
            margin-bottom: 1.5em;
        }
        .controls {
            display: flex;
            flex-direction: column;
            gap: 1.5em;
            margin-bottom: 2em;
        }
        .buttons {
            display: flex;
            gap: 1em;
        }
        button {
            font-size: 1rem;
            padding: 0.8em 1.5em;
            border-radius: 8px;
            border: none;
            cursor: pointer;
            transition: all 0.2s ease;
            font-weight: 600;
        }
        #start-btn {
            background-color: #27ae60;
            color: white;
            flex-grow: 1;
        }
        #start-btn:hover { background-color: #2ecc71; }
        #start-btn:disabled { background-color: #95a5a6; cursor: not-allowed; }
        
        #stop-btn {
            background-color: #c0392b;
            color: white;
            flex-grow: 1;
        }
        #stop-btn:hover { background-color: #e74c3c; }
        #stop-btn:disabled { background-color: #95a5a6; cursor: not-allowed; }
        
        .selectors {
            display: flex;
            gap: 1em;
            justify-content: space-between;
        }
        .form-group {
            display: flex;
            flex-direction: column;
            gap: 0.5em;
            flex-grow: 1;
        }
        label {
            font-weight: 600;
            color: #555;
            font-size: 0.9rem;
        }
        select {
            font-size: 1rem;
            padding: 0.8em;
            border: 1px solid #ddd;
            border-radius: 8px;
            background-color: #fff;
            width: 100%;
        }
        .status {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 0.8em;
            margin-bottom: 1.5em;
            min-height: 25px;
        }
        .vad-light {
            width: 20px;
            height: 20px;
            background-color: #bdc3c7; /* Gris */
            border-radius: 50%;
            transition: background-color 0.2s;
        }
        .vad-light.speaking {
            background-color: #27ae60; /* Verde */
            animation: pulse 1s infinite;
        }
        #status-log {
            font-size: 1rem;
            color: #34495e;
            font-weight: 500;
        }
        #output-container {
            background: #f9f9f9;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            min-height: 150px;
            max-height: 300px;
            overflow-y: auto;
            padding: 1.5em;
            color: #2c3e50;
            line-height: 1.6;
        }
        #output-container p {
            margin: 0 0 0.8em 0;
            padding-bottom: 0.8em;
            border-bottom: 1px solid #eee;
        }
        #output-container p:last-child {
            margin-bottom: 0;
            border-bottom: none;
        }
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(39, 174, 96, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(39, 174, 96, 0); }
            100% { box-shadow: 0 0 0 0 rgba(39, 174, 96, 0); }
        }
    </style>
</head>
<body>

    <main>
        <h1>Traductor de Voz en Tiempo Real</h1>

        <div class="controls">
            <div class="buttons">
                <button id="start-btn">Iniciar Traducción</button>
                <button id="stop-btn" disabled>Detener</button>
            </div>
            <div class="selectors">
                <div class="form-group">
                    <label for="model-select">Modelo Whisper:</label>
                    <select id="model-select">
                        <option value="tiny">Tiny</option>
                        <option value="base" selected>Base</option>
                        <option value="small">Small</option>
                        <option value="medium">Medium</option>
                        <option value="large-v3">Large-v3</option>
                    </select>
                </div>
                <div class="form-group">
                    <label for="language-select">Idioma (Fuente):</label>
                    <select id="language-select">
                        <option value="">Auto-Detectar</option>
                        <option value="es">Español</option>
                        <option value="en">Inglés</option>
                        <option value="fr">Francés</option>
                        <option value="de">Alemán</option>
                        <option value="ja">Japonés</option>
                        <option value="zh">Chino</option>
                        <option value="it">Italiano</option>
                    </select>
                </div>
            </div>
        </div>

        <div class="status">
            <div class="vad-light" id="vad-light"></div>
            <div id="status-log">Haz clic en "Iniciar" para comenzar</div>
        </div>

        <div id="output-container"></div>
    </main>

    <script type="module">
        // --- Referencias al DOM ---
        const startBtn = document.getElementById('start-btn');
        const stopBtn = document.getElementById('stop-btn');
        const statusLog = document.getElementById('status-log');
        const vadLight = document.getElementById('vad-light');
        const outputDiv = document.getElementById('output-container');
        const modelSelect = document.getElementById('model-select');
        const languageSelect = document.getElementById('language-select');

        // --- Configuración de APIs y Audio ---
        const VAD_API_URL = "ws://127.0.0.1:8001/ws/vad";
        const WHISPER_API_URL = "http://127.0.0.1:8000/translate";
        
        const SAMPLE_RATE = 16000;
        const PRE_ROLL_TIME = 3; // Segundos de audio *antes* de speech_start
        const POST_ROLL_TIME = 3; // Segundos de audio *después* de speech_end

        // Convertir tiempo a muestras
        const PRE_ROLL_SAMPLES = SAMPLE_RATE * PRE_ROLL_TIME;
        
        // --- Variables de Estado Globales ---
        let socket = null;
        let audioContext = null;
        let workletNode = null;
        let mediaStreamSource = null;

        // Buffers de audio:
        // preRollBuffer: Almacena constantemente los últimos 2 seg
        let preRollBuffer = new Float32Array(0);
        // speechBuffer: Almacena el audio que se enviará a Whisper
        let speechBuffer = new Float32Array(0);
        
        // Estado de grabación (controlado por VAD)
        let isRecording = false;
        // Temporizador para el post-roll
        let postRollTimer = null;

        /**
         * Actualiza el log de estado y el estilo de la luz VAD.
         * @param {string} message - El texto a mostrar.
         * @param {'idle' | 'processing' | 'error' | 'speaking'} state - El estado visual.
         */
        function log(message, state = 'idle') {
            statusLog.textContent = message;
            if (state === 'speaking') {
                vadLight.classList.add('speaking');
            } else {
                vadLight.classList.remove('speaking');
            }
            if (state === 'error') {
                statusLog.style.color = '#c0392b';
            } else {
                statusLog.style.color = '#34495e';
            }
        }

        /**
         * Maneja los datos de audio entrantes desde el AudioWorklet.
         * @param {Float32Array} audioData - El chunk de audio del micrófono.
         */
        function handleAudioData(audioData) {
            if (isRecording) {
                // Si estamos grabando (VAD activo), añadir al speechBuffer
                const newBuffer = new Float32Array(speechBuffer.length + audioData.length);
                newBuffer.set(speechBuffer);
                newBuffer.set(audioData, speechBuffer.length);
                speechBuffer = newBuffer;
            } else {
                // Si no estamos grabando, añadir al preRollBuffer
                const newBuffer = new Float32Array(preRollBuffer.length + audioData.length);
                newBuffer.set(preRollBuffer);
                newBuffer.set(audioData, preRollBuffer.length);
                
                // Recortar el preRollBuffer para que contenga solo los últimos PRE_ROLL_SAMPLES
                if (newBuffer.length > PRE_ROLL_SAMPLES) {
                    preRollBuffer = newBuffer.slice(newBuffer.length - PRE_ROLL_SAMPLES);
                } else {
                    preRollBuffer = newBuffer;
                }
            }
        }
        
        /**
         * Envía el audio acumulado a la API de Whisper.
         * Esta función se llama por el temporizador de post-roll.
         */
        async function sendToWhisper() {
            if (speechBuffer.length < SAMPLE_RATE * 0.5) { // No enviar si es menos de 0.5 seg
                log("Audio demasiado corto, descartado.", "idle");
                speechBuffer = new Float32Array(0); // Limpiar buffer
                return;
            }
            
            log("Traduciendo audio...", "processing");
            
            // Crear el Blob WAV
            const wavBlob = createWavBlob(speechBuffer, SAMPLE_RATE);
            
            // Limpiar el speechBuffer INMEDIATAMENTE después de crear el Blob
            speechBuffer = new Float32Array(0);
            
            const formData = new FormData();
            formData.append('audio_file', wavBlob, 'segment.wav');
            formData.append('model_size', modelSelect.value);
            formData.append('language', languageSelect.value);

            try {
                const response = await fetch(WHISPER_API_URL, {
                    method: 'POST',
                    body: formData,
                });

                if (!response.ok) {
                    throw new Error(`Error de red: ${response.statusText}`);
                }

                const data = await response.json();
                
                // CAMBIO: Se busca 'data.result_text'
                const translationText = data.result_text; 

                // Verificar que 'translationText' sea un string antes de usar .trim()
                if (typeof translationText === 'string') {
                    const trimmedText = translationText.trim();
                    if (trimmedText) {
                        outputDiv.innerHTML += `<p>${trimmedText}</p>`;
                        outputDiv.scrollTop = outputDiv.scrollHeight; // Auto-scroll
                    }
                    // Si trimmedText está vacío (audio silencioso), no se muestra nada.
                } else {
                    console.warn("La respuesta de Whisper no contenía una clave 'result_text' válida.");
                }
                
                log("Escuchando...", "idle");

            } catch (error) {
                console.error('Error al enviar a Whisper:', error);
                log(`Error de Whisper: ${error.message}`, "error");
            }
        }

        /**
         * Función para detener todo (botón de stop o error).
         */
        function stopDetection() {
            if (socket) {
                socket.close();
                socket = null;
            }
            if (workletNode) {
                workletNode.port.onmessage = null;
                workletNode.disconnect();
                workletNode = null;
            }
            if (mediaStreamSource) {
                mediaStreamSource.mediaStream.getTracks().forEach(track => track.stop());
                mediaStreamSource.disconnect();
                mediaStreamSource = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            if (postRollTimer) {
                clearTimeout(postRollTimer);
                postRollTimer = null;
            }
            
            // Limpiar buffers y estado
            preRollBuffer = new Float32Array(0);
            speechBuffer = new Float32Array(0);
            isRecording = false;

            log('Haz clic en "Iniciar" para comenzar', 'idle');
            startBtn.disabled = false;
            stopBtn.disabled = true;
            modelSelect.disabled = false;
            languageSelect.disabled = false;
        }

        // --- Event Listener del Botón de Inicio ---
        startBtn.addEventListener('click', async () => {
            log("Iniciando...", "processing");
            startBtn.disabled = true;
            stopBtn.disabled = false;
            modelSelect.disabled = true;
            languageSelect.disabled = true;

            try {
                // 1. Conectar al WebSocket de VAD
                socket = new WebSocket(VAD_API_URL);

                socket.onopen = () => {
                    log("VAD conectado. Solicitando micrófono...", "processing");
                };

                socket.onclose = () => {
                    log("VAD desconectado.", "idle");
                    stopDetection();
                };

                socket.onerror = (err) => {
                    log("Error de WebSocket VAD.", "error");
                    console.error("Error de WebSocket:", err);
                    stopDetection();
                };

                // 2. Escuchar eventos del servidor VAD
                socket.onmessage = (event) => {
                    const msg = JSON.parse(event.data);
                    
                    if (msg.event === "speech_start") {
                        log("Hablando...", "speaking");
                        
                        // Si hay un temporizador de post-roll corriendo, cancelarlo.
                        // Esto une frases que están muy juntas.
                        if (postRollTimer) {
                            clearTimeout(postRollTimer);
                            postRollTimer = null;
                        }

                        // Si no estábamos grabando, volcamos el pre-roll
                        if (!isRecording) {
                            speechBuffer = new Float32Array(preRollBuffer);
                        }
                        
                        isRecording = true;

                    } else if (msg.event === "speech_end") {
                        log("Fin de voz detectado...", "processing");
                        
                        // Solo si estábamos grabando, iniciamos el post-roll
                        if (isRecording) {
                            isRecording = false;
                            
                            // Iniciar temporizador para enviar a Whisper
                            postRollTimer = setTimeout(() => {
                                sendToWhisper();
                                postRollTimer = null;
                            }, POST_ROLL_TIME * 1000);
                        }
                    } else if (msg.error) {
                        log(`Error del servidor VAD: ${msg.error}`, "error");
                    }
                };

                // 3. Configurar AudioContext y Worklet
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: SAMPLE_RATE
                });
                
                // Política de Autoplay: Reanudar el contexto
                await audioContext.resume();

                // 4. Crear el Worklet
                const workletURL = URL.createObjectURL(new Blob([`
                    class VADAudioProcessor extends AudioWorkletProcessor {
                        process(inputs, outputs, parameters) {
                            const inputChannel = inputs[0][0];
                            if (inputChannel) {
                                this.port.postMessage(inputChannel);
                            }
                            return true;
                        }
                    }
                    registerProcessor('vad-audio-processor', VADAudioProcessor);
                `], { type: 'application/javascript' }));

                await audioContext.audioWorklet.addModule(workletURL);

                workletNode = new AudioWorkletNode(audioContext, 'vad-audio-processor');

                // 5. Configurar el listener del Worklet
                workletNode.port.onmessage = (event) => {
                    // event.data es un Float32Array
                    handleAudioData(event.data);
                    
                    // Enviar audio al servidor VAD
                    if (socket && socket.readyState === WebSocket.OPEN) {
                        socket.send(event.data.buffer);
                    }
                };

                // 6. Obtener micrófono y conectar el grafo de audio
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Comprobar si el contexto sigue vivo (evitar race condition)
                if (!audioContext) {
                    throw new Error("El contexto de audio se cerró debido a un error de conexión.");
                }

                mediaStreamSource = audioContext.createMediaStreamSource(stream);
                mediaStreamSource.connect(workletNode);
                workletNode.connect(audioContext.destination);

                log("Micrófono activo. Escuchando...", "idle");

            } catch (error) {
                log(`Error al iniciar: ${error.message}`, "error");
                console.error("Error en startBtn:", error);
                stopDetection();
            }
        });

        stopBtn.addEventListener('click', stopDetection);


        // --- Funciones de Utilidad (Crear WAV) ---
        function createWavBlob(audioData, sampleRate) {
            const buffer = new ArrayBuffer(44 + audioData.length * 2);
            const view = new DataView(buffer);
            
            writeString(view, 0, 'RIFF');
            view.setUint32(4, 36 + audioData.length * 2, true);
            writeString(view, 8, 'WAVE');
            writeString(view, 12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true); // PCM
            view.setUint16(22, 1, true); // 1 canal
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true); // Byte rate
            view.setUint16(32, 2, true); // Block align
            view.setUint16(34, 16, true); // 16-bit
            writeString(view, 36, 'data');
            view.setUint32(40, audioData.length * 2, true);
            
            // Escribir las muestras PCM
            let offset = 44;
            for (let i = 0; i < audioData.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, audioData[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            
            return new Blob([view], { type: 'audio/wav' });
        }

        function writeString(view, offset, string) {
            for (let i = 0; i < string.length; i++) {
                view.setUint8(offset + i, string.charCodeAt(i));
            }
        }

    </script>
</body>
</html>

